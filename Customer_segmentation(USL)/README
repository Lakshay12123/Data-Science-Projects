# 🧠 Unsupervised Clustering with DBSCAN, PCA & Outlier Detection

This project explores the power of **unsupervised learning techniques** using a large dataset with over 350,000 records and 7 features. The core focus lies in **dimensionality reduction, anomaly detection, and density-based clustering** to reveal hidden patterns in the data.

---

## 🔍 Key Objectives

- 📉 **Reduce dimensionality** of high-dimensional data using PCA for better visualization and performance.
- 🧩 **Detect outliers** using Isolation Forest to clean the dataset before clustering.
- 📌 **Apply DBSCAN** clustering to uncover natural groups in the data without assuming the number of clusters.
- 🎯 **Tune hyperparameters** (like `eps` in DBSCAN) using Elbow Methods and evaluation metrics.

---

## 🧰 Tools & Libraries Used

- **Python 3.10+**
- `pandas`, `numpy` – for data wrangling
- `matplotlib`, `seaborn` – for visualization
- `scikit-learn` – for PCA, DBSCAN, IsolationForest, and clustering metrics
- `plotly` – (optional) for interactive 3D plots

---

## ⚙️ Techniques Used

### 1. 🧼 Data Preprocessing
- Standard scaling using `StandardScaler`
- Removing anomalies using `IsolationForest`

### 2. 📉 Dimensionality Reduction
- **PCA (Principal Component Analysis)** to reduce features to 3D for plotting

### 3. 🔎 Clustering
- **DBSCAN (Density-Based Spatial Clustering)**
- Tuning `eps` using:
  - **Silhouette Score**
  - **Calinski-Harabasz Score**
  - **Elbow Plot**

### 4. 📊 Evaluation Metrics
- **Silhouette Score** – Measures how well samples are clustered
- **Calinski-Harabasz Index** – Ratio of between-cluster dispersion to within-cluster

---

## 📌 Visualizations Included

- Countplot showing label distribution
- PCA-transformed 3D scatter plot of clusters
- Elbow plot for DBSCAN `eps` tuning using dual axes
- Cluster-wise performance metrics

---

💡 Future Improvements
While the current project provides a strong foundation for unsupervised clustering, there are several areas for enhancement:

🚀 Model & Algorithm Enhancements
Try alternative clustering algorithms:
-  HDBSCAN (Hierarchical DBSCAN) – more flexible with clusters of varying density
- OPTICS – better for ordering points in space
- Auto-tuning DBSCAN parameters using grid search or Bayesian optimization

📈 Feature Engineering
- Apply feature selection techniques to identify the most influential features.
- Use autoencoders for more advanced nonlinear dimensionality reduction.

🧪 Experimentation
- Benchmark clustering results with internal/external validation metrics:
- Davies–Bouldin Index
- Adjusted Rand Index (if ground truth is available)
- Analyze cluster stability by running DBSCAN on different random subsamples.

📊 Visualization
- Use interactive 3D visualizations with Plotly for better exploration.
- Build a dashboard (e.g., with Streamlit) to allow dynamic cluster exploration.

📦 Production & Deployment
- Package the entire pipeline into a modular Python script or API.
- Prepare a streamlined CLI tool to perform DBSCAN clustering on any given dataset.

---
                     
🤝 Contributing
Feel free to fork the project, improve visualizations, or test other clustering techniques like HDBSCAN or OPTICS.

